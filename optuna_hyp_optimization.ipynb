{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsQiXjZ0LMC-"
      },
      "source": [
        "Install and import **Optuna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zVRyGSGK430"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4euIO0OOJV_c"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "from PIL import Image\n",
        "import glob\n",
        "import time, copy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler, Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models import ResNet152_Weights\n",
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl_1u-OI3vty",
        "outputId": "2fb792b0-0d14-4b9f-86fe-5455be45befd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRefGePR3ylf"
      },
      "outputs": [],
      "source": [
        "#save paths\n",
        "save_name = 'optuna_hyp_optimization'\n",
        "path_graph = '/content/drive/MyDrive/resnet152/risultati/grafici/'\n",
        "path_model = '/content/drive/MyDrive/resnet152/risultati/modelli/'\n",
        "path_pd = '/content/drive/MyDrive/resnet152/risultati/acc_loss/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3eW6soc34R6",
        "outputId": "fd6e8084-9220-4010-c830-4ef8d74f9845"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['non_spurious', 'spurious']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "path_folder = '/content/drive/MyDrive/backups/wikiAum_resized2.0_splitted'\n",
        "\n",
        "train_folder_path = path_folder + '/train'\n",
        "test_folder_path = path_folder + '/test'\n",
        "val_folder_path = path_folder + '/val' \n",
        "\n",
        "\n",
        "train_foto_paths = [] \n",
        "test_foto_paths = [] \n",
        "val_foto_paths = [] \n",
        "classes = [] \n",
        "\n",
        "# get all the paths from train_folder_path and append image paths and class to to respective lists\n",
        "for data_path in glob.glob(train_folder_path + '/*'):\n",
        "    classes.append(data_path.split('/')[-1]) \n",
        "    train_foto_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "for data_path in glob.glob(test_folder_path + '/*'):\n",
        "    test_foto_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "for data_path in glob.glob(val_folder_path + '/*'):\n",
        "    val_foto_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnDYsqEb34YN"
      },
      "outputs": [],
      "source": [
        "train_paths = train_foto_paths[0] + train_foto_paths[1]\n",
        "test_paths = test_foto_paths[0] + test_foto_paths[1]\n",
        "val_paths = val_foto_paths[0] + val_foto_paths[1]\n",
        "\n",
        "train_paths = list((np.array(train_paths).flatten()))\n",
        "test_paths = list((np.array(test_paths).flatten()))\n",
        "val_paths = list((np.array(val_paths).flatten()))\n",
        "\n",
        "\n",
        "random.shuffle(train_paths)\n",
        "random.shuffle(val_paths)\n",
        "random.shuffle(test_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK0d77DZ3-O3",
        "outputId": "7bd126b9-9952-488e-ad92-350ef745965d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'non_spurious': 0, 'spurious': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
        "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKRgVDy334eo"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomVerticalFlip(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                                       ])#resize if needed\n",
        "\n",
        "val_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                           [0.229, 0.224, 0.225])\n",
        "                                    ])#resize if needed\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                          [0.229, 0.224, 0.225])\n",
        "                                      ])#resize if needed\n",
        "] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HOpgAAu4CJA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#   Define Dataset Class\n",
        "\n",
        "\n",
        "class Spuriedata(Dataset):\n",
        "    def __init__(self, image_paths, transform):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filepath = self.image_paths[idx]\n",
        "        #image = io.imread(image_filepath,0,pilmode=\"RGB\")\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        \n",
        "        label = image_filepath.split('/')[-2]\n",
        "        label = class_to_idx[label]\n",
        "        image = self.transform(image)\n",
        "            \n",
        "        \n",
        "        return image, label\n",
        "    \n",
        "#######################################################\n",
        "#                  Create Dataset\n",
        "#######################################################\n",
        "\n",
        "train_dataset = Spuriedata(train_paths,train_transforms)\n",
        "val_dataset = Spuriedata(val_paths,val_transforms) \n",
        "test_dataset = Spuriedata(test_paths,test_transforms)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKVZRODj4EHp"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oUfPvZ9HLEk"
      },
      "outputs": [],
      "source": [
        "#In order to get a pretrained model by its name, we will add a function get_model:\n",
        "def get_model(model_name: str = \"resnet152_droput5\"):\n",
        "\n",
        "  if model_name == \"resnet152_droput5\":\n",
        "    model = torchvision.models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "                        nn.Dropout(p=0.5, inplace=False),\n",
        "                        nn.Linear(in_features=2048, out_features=1024, bias=True),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.5, inplace=False),\n",
        "                        nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.5),\n",
        "                        nn.Linear(512, 256),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(256, 2)\n",
        "                        )\n",
        "      \n",
        "  \n",
        "  elif model_name == \"resnet152_droputDownScaled\":\n",
        "    model = torchvision.models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "                        nn.Dropout(p=0.5, inplace=False),\n",
        "                        nn.Linear(in_features=2048, out_features=1024, bias=True),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.4, inplace=False),\n",
        "                        nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.3),\n",
        "                        nn.Linear(512, 256),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(256, 2)\n",
        "                        )\n",
        "                        \n",
        "\n",
        "  \n",
        "  elif model_name == \"resnet152_droput2\":\n",
        "    model = torchvision.models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc =nn.Sequential(\n",
        "                        nn.Dropout(p=0.2, inplace=False),\n",
        "                        nn.Linear(in_features=2048, out_features=1024, bias=True),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.2, inplace=False),\n",
        "                        nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.2),\n",
        "                        nn.Linear(512, 256),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(256, 2)\n",
        "                        )\n",
        "    \n",
        "  elif model_name == \"resnet152_droputUpScaled\":\n",
        "    model = torchvision.models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "                        nn.Dropout(p=0.3, inplace=False),\n",
        "                        nn.Linear(in_features=2048, out_features=1024, bias=True),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout(p=0.4, inplace=False),\n",
        "                        nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.5),\n",
        "                        nn.Linear(512, 256),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(256, 2)\n",
        "                        )\n",
        "\n",
        "    \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g72MrxTE_M4S"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub5tz6odL-ss"
      },
      "source": [
        "The following function will be used to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pthOavDA9d-Q"
      },
      "outputs": [],
      "source": [
        "def train_model(trial, model, criterion, optimizer,scheduler, num_epochs=30):\n",
        "  start_time = time.time() #(for showing time)\n",
        "  t_losses   = []\n",
        "  v_losses   = []\n",
        "  t_acc = []\n",
        "  v_acc = []\n",
        "  best_acc = 0\n",
        "  best_loss = math.inf\n",
        "  for epoch in range(num_epochs):\n",
        "    #(loop for every epoch)\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1)) #(printing message)\n",
        "    \"\"\" Training Phase \"\"\"\n",
        "    model.train()    #(training model)\n",
        "    running_loss = 0.   #(set loss 0)\n",
        "    running_corrects = 0 \n",
        "    # load a batch data of images\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device) \n",
        "      # forward inputs and get output\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(images)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      loss = criterion(outputs, labels)\n",
        "      # get loss value and update the network weights\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item() * images.size(0)\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "    scheduler.step()    \n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    t_losses.append(epoch_loss)\n",
        "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
        "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}m'.format(epoch, epoch_loss, epoch_acc, (time.time() -start_time)//60))\n",
        "    t_acc.append(epoch_acc)\n",
        "    \n",
        "    \"\"\" eval Phase \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      running_loss = 0.\n",
        "      running_corrects = 0\n",
        "      for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "      epoch_loss = running_loss / len(val_dataset)\n",
        "      v_losses.append(epoch_loss)\n",
        "      epoch_acc = running_corrects / len(val_dataset) * 100.\n",
        "      print('[Val #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}m'.format(epoch, epoch_loss, epoch_acc, (time.time()- start_time)//60))\n",
        "      v_acc.append(epoch_acc)\n",
        "      if epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        torch.save(model, path_model + save_name + '_acc.pth')\n",
        "        if epoch_loss < best_loss:\n",
        "          best_loss = epoch_loss\n",
        "          best_model_wts = copy.deepcopy(model.state_dict())\n",
        "          torch.save(model, path_model + save_name + '_loss.pth')\n",
        "                \n",
        "      print()\n",
        "        \n",
        "      trial.report(epoch_acc, epoch)\n",
        "      if trial.should_prune():\n",
        "        raise optuna.TrialPruned()\n",
        "\n",
        "  time_elapsed = time.time() - start_time\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "      time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model, best_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVAypp49Mwgr"
      },
      "source": [
        "We need to create the **Objective Function**. It takes a configuration of hyperparameters and returns its evaluation score (Objective value). By maximizing or minimizing the **Objective Function**, Optuna solves the problem of hyperparameter optimization.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0JK8jxlHW3W"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  params = {\n",
        "      \"model_name\": trial.suggest_categorical('model_name',[\"resnet152_droput5\", \"resnet152_droputDownScaled\", \"resnet152_droput2\",\"resnet152_droputUpScaled\"]),\n",
        "      \"lr\": trial.suggest_loguniform('lr', 1e-6, 1e-2),\n",
        "      \"optimizer_name\": trial.suggest_categorical('optimizer_name',[\"SGD\", \"Adam\"])}\n",
        "    \n",
        "    # Get pretrained model\n",
        "  model = get_model(params[\"model_name\"])\n",
        "  model = model.to(device)\n",
        "    \n",
        "    # Define criterion\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Configure optimizer\n",
        "  optimizer = getattr(\n",
        "      torch.optim, params[\"optimizer_name\"]\n",
        "    )(model.parameters(), lr=params[\"lr\"])\n",
        "  scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "    \n",
        "    # Train model\n",
        "  best_model, best_acc = train_model(trial, model, criterion, optimizer,scheduler)\n",
        "    \n",
        "  return best_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g1hzClHNcgf"
      },
      "source": [
        "To start optimizing our **Objective Function**, we create a new **study**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_qEl_XlRHaO3"
      },
      "outputs": [],
      "source": [
        "# sampler: We want to use a TPE sampler\n",
        "# pruner: We use a MedianPruner in order to interrupt unpromising trials\n",
        "# direction: The direction of study is “maximize” because we want to maximize the accuracy\n",
        "# n_trials: Number of trials\n",
        "\n",
        "sampler = optuna.samplers.TPESampler()    \n",
        "study = optuna.create_study(\n",
        "    sampler=sampler,\n",
        "    pruner=optuna.pruners.MedianPruner(\n",
        "        n_startup_trials=3, n_warmup_steps=5, interval_steps=3\n",
        "    ),\n",
        "    direction='maximize')\n",
        "study.optimize(func=objective, n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NyrLHug3He93"
      },
      "outputs": [],
      "source": [
        "print(\"Best trial: \")\n",
        "print(study.best_trial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5kzTFMJK5voH"
      },
      "outputs": [],
      "source": [
        "model = torch.load(path_model + save_name + '_loss.pth', map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0o0SKZxVtoae"
      },
      "outputs": [],
      "source": [
        "true_labels = []\n",
        "preds       = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    \n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    logits = model(images)    \n",
        "      \n",
        "    curr_preds = torch.argmax(F.softmax(logits, dim=-1), dim=-1)\n",
        "    true_labels.extend(labels.view(-1).tolist())\n",
        "    preds.extend(curr_preds.view(-1).tolist())\n",
        "print('{}classification report'.format(classification_report(true_labels, preds)))\n",
        "report = classification_report(true_labels, preds, output_dict=True)\n",
        "df = pd.DataFrame(report).transpose()\n",
        "df.to_csv(path_pd + save_name + '_report')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iPDdfj7ltpgN"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.figure(figsize=(3,3))\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dtiuda2ztplO"
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=4):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                if classes[preds[j]] != classes[labels[j]]:\n",
        "                  images_so_far += 1\n",
        "                  ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                  ax.axis('off')\n",
        "                  ax.set_title(f'predicted: {classes[preds[j]]}\\nlabel: {classes[labels[j]]}')\n",
        "                  imshow(inputs.cpu().data[j].permute(0,2,1))\n",
        "                else: continue\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qooiENNUtppo"
      },
      "outputs": [],
      "source": [
        "visualize_model(model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}