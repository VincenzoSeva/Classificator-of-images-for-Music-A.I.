{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZSGhHIfpWcSE"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "from PIL import Image\n",
        "import glob\n",
        "import time, copy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler, Adam, SGD\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models import ResNet152_Weights, ResNet18_Weights\n",
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oTlgT57WCnsR"
      },
      "outputs": [],
      "source": [
        "#save paths\n",
        "save_name = 'wikiart_model'\n",
        "path_graph = '/content/drive/MyDrive/resnet152/risultati/presentazione/grafici/'\n",
        "path_model = '/content/drive/MyDrive/resnet152/risultati/modelli/'\n",
        "path_pd = '/content/drive/MyDrive/resnet152/risultati/presentazione/csv/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMBZ7pi2ZRXG",
        "outputId": "92fde991-e011-4f15-aabd-23266a07100d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['non_spurious', 'spurious']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "path_folder = '/content/drive/MyDrive/backups/wikiAum_resized2.0_splitted'\n",
        "\n",
        "train_folder_path = path_folder + '/train'\n",
        "test_folder_path = path_folder + '/test'\n",
        "val_folder_path = path_folder + '/val' \n",
        "\n",
        "\n",
        "train_foto_paths = [] #to store image paths in list\n",
        "test_foto_paths = [] #to store image paths in list\n",
        "val_foto_paths = [] #to store image paths in list\n",
        "classes = [] #to store class values\n",
        "\n",
        "\n",
        "# get all the paths from train_folder_path and append image paths and class to to respective lists\n",
        "\n",
        "for data_path in glob.glob(train_folder_path + '/*'):\n",
        "    classes.append(data_path.split('/')[-1]) \n",
        "    train_foto_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "for data_path in glob.glob(test_folder_path + '/*'):\n",
        "    test_foto_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "for data_path in glob.glob(val_folder_path + '/*'):\n",
        "    val_foto_paths.append(glob.glob(data_path + '/*'))\n",
        "\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VDW2bEVYZUVP"
      },
      "outputs": [],
      "source": [
        "train_paths = train_foto_paths[0] + train_foto_paths[1]\n",
        "test_paths = test_foto_paths[0] + test_foto_paths[1]\n",
        "val_paths = val_foto_paths[0] + val_foto_paths[1]\n",
        "\n",
        "train_paths = list((np.array(train_paths).flatten()))\n",
        "test_paths = list((np.array(test_paths).flatten()))\n",
        "val_paths = list((np.array(val_paths).flatten()))\n",
        "\n",
        "\n",
        "random.shuffle(train_paths)\n",
        "random.shuffle(val_paths)\n",
        "random.shuffle(test_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNdlPlHlZX33",
        "outputId": "8deec80e-1ee0-4be1-f6b4-64aa54c1af8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nature': 0, 'city': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
        "class_to_idx = {value:key for key,value in idx_to_class.items()}\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "43Uw79MNZbkA"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomVerticalFlip(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                                       ])#resize if needed\n",
        "\n",
        "val_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                           [0.229, 0.224, 0.225])\n",
        "                                    ])#resize if needed\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                          [0.229, 0.224, 0.225])\n",
        "                                      ])#resize if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDLbu3cEa5IS",
        "outputId": "41cfed82-3007-4b18-b773-0d698f9f6f0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4222, 908, 904)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\n",
        "#  Define Dataset Class\n",
        "\n",
        "class Spuriedata(Dataset):\n",
        "    def __init__(self, image_paths, transform):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filepath = self.image_paths[idx]\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        \n",
        "        label = image_filepath.split('/')[-2]\n",
        "        label = class_to_idx[label]\n",
        "        image = self.transform(image)\n",
        "            \n",
        "        \n",
        "        return image, label\n",
        "\n",
        "# Create Dataset\n",
        "\n",
        "train_dataset = Spuriedata(train_paths,train_transforms)\n",
        "val_dataset = Spuriedata(val_paths,val_transforms) \n",
        "test_dataset = Spuriedata(test_paths,test_transforms)\n",
        "\n",
        "len(train_dataset),len(test_dataset),len(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "S6HmfMGGZjA_"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6WvCc1ordyKB"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True #the net is unfrozen\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(nn.Linear(2048, 1024),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.4),\n",
        "                        nn.Linear(1024, 512),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.4),\n",
        "                        nn.Linear(512, 128),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(0.4),\n",
        "                        nn.Linear(128, 64),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(64, 2)\n",
        "                        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycUwRcRGZlyH",
        "outputId": "fee81808-01aa-4fe6-87bb-6682e9e46f1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#setting hyperparameters\n",
        "optimizer = Adam(model.parameters(), lr=0.001) \n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#moving to gpu if possible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=model.to(device)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPWD8aMFZong"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30   \n",
        "start_time = time.time() \n",
        "t_losses   = []\n",
        "v_losses   = []\n",
        "t_acc = []\n",
        "v_acc = []\n",
        "best_acc = 0\n",
        "best_loss = math.inf\n",
        "for epoch in range(num_epochs): \n",
        "    \n",
        "    print(\"Epoch {} running\".format(epoch)) \n",
        "    \"\"\" Training Phase \"\"\"\n",
        "    \n",
        "    model.train()    #training phase\n",
        "    running_loss = 0.   \n",
        "    running_corrects = 0 \n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device) \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    scheduler.step()    \n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    t_losses.append(epoch_loss)\n",
        "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
        "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}m'.format(epoch, epoch_loss, epoch_acc, (time.time() -start_time)//60))\n",
        "    t_acc.append(epoch_acc)\n",
        "    \n",
        "    #eval phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0.\n",
        "        running_corrects = 0\n",
        "\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(val_dataset)\n",
        "        v_losses.append(epoch_loss)\n",
        "        epoch_acc = running_corrects / len(val_dataset) * 100.\n",
        "        print('[Val #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}m'.format(epoch, epoch_loss, epoch_acc, (time.time()- start_time)//60))\n",
        "        v_acc.append(epoch_acc)\n",
        "        \n",
        "        if epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model, path_model + save_name + '_acc.pth')\n",
        "                torch.save(model, save_name + '_acc.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IK-b5GMZZr6o",
        "outputId": "64042f32-adf9-410c-85b1-a03de78a986e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#plotting results\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(t_losses, 'b-x', label='train_loss')\n",
        "plt.plot(v_losses, 'r-x', label='validation_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid(axis='y')\n",
        "plt.legend()\n",
        "plt.ylim([0, .8])\n",
        "plt.title('Loss vs. No. of epochs')\n",
        "plt.savefig( path_graph + save_name + '.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HgGOlr2KM5rs"
      },
      "outputs": [],
      "source": [
        "#saving the loss plot \n",
        "def nump(lista):\n",
        "  a = [n.cpu() for n in lista]\n",
        "  b = [n.numpy() for n in a]\n",
        "  c = [float('{:.5f}'.format(n)) for n in b]\n",
        "  return c\n",
        "\n",
        "tn_acc = nump(t_acc)\n",
        "vn_acc = nump(v_acc)\n",
        "\n",
        "df = pd.DataFrame({'epoch': range(30), 't_loss': t_losses, 'v_loss': v_losses, 't_acc': tn_acc, 'v_acc': vn_acc})\n",
        "\n",
        "df.to_csv(path_pd + save_name + '_loss')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using the best model \n",
        "model = torch.load(path_model + save_name + '_acc.pth', map_location=device)"
      ],
      "metadata": {
        "id": "T_asCEHLcN67"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNk_ubI9Zybf"
      },
      "outputs": [],
      "source": [
        "#prediction on test/saving pred.\n",
        "true_labels = []\n",
        "preds       = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    \n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    logits = model(images)    \n",
        "      \n",
        "    curr_preds = torch.argmax(F.softmax(logits, dim=-1), dim=-1)\n",
        "    true_labels.extend(labels.view(-1).tolist())\n",
        "    preds.extend(curr_preds.view(-1).tolist())\n",
        "print('{}classification report'.format(classification_report(true_labels, preds)))\n",
        "report = classification_report(true_labels, preds, output_dict=True)\n",
        "df = pd.DataFrame(report).transpose()\n",
        "df.to_csv(path_pd + save_name + '_report')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcjNLPasg2dd"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "   #imshow for tensor\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.figure(figsize=(3,3))\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z47VV6juhFoB"
      },
      "outputs": [],
      "source": [
        "#function for qualitative test\n",
        "def visualize_model(model, num_images=4):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                if classes[preds[j]] == classes[labels[j]]:\n",
        "                  images_so_far += 1\n",
        "                  ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                  ax.axis('off')\n",
        "                  ax.set_title(f'predicted: {classes[preds[j]]}\\nlabel: {classes[labels[j]]}')\n",
        "                  imshow(inputs.cpu().data[j].permute(0,2,1))\n",
        "                else: continue\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8WRS6EthLfv"
      },
      "outputs": [],
      "source": [
        "visualize_model(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}